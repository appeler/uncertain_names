{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f54935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a4124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nonconformist.nc import NcFactory\n",
    "from nonconformist.cp import IcpClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae725d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "      <th>name_first</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>841323</th>\n",
       "      <td>Torres</td>\n",
       "      <td>Jose</td>\n",
       "      <td>hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408926</th>\n",
       "      <td>Da Silva</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733118</th>\n",
       "      <td>Mc Ghee</td>\n",
       "      <td>Sandra</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13104513</th>\n",
       "      <td>Karam</td>\n",
       "      <td>MELINDA</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9156114</th>\n",
       "      <td>Brewer</td>\n",
       "      <td>LAIA</td>\n",
       "      <td>nh_black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076722</th>\n",
       "      <td>Antunez Avila</td>\n",
       "      <td>Robert</td>\n",
       "      <td>hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023679</th>\n",
       "      <td>Davis</td>\n",
       "      <td>WYATT</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846252</th>\n",
       "      <td>Scott</td>\n",
       "      <td>Jacquelyn</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5959131</th>\n",
       "      <td>Parton</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12031764</th>\n",
       "      <td>Knapp</td>\n",
       "      <td>Liza</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name_last name_first      race\n",
       "841323           Torres       Jose  hispanic\n",
       "1408926        Da Silva     Amanda  nh_white\n",
       "1733118         Mc Ghee     Sandra  nh_white\n",
       "13104513          Karam    MELINDA  nh_white\n",
       "9156114          Brewer       LAIA  nh_black\n",
       "...                 ...        ...       ...\n",
       "3076722   Antunez Avila     Robert  hispanic\n",
       "10023679          Davis      WYATT  nh_white\n",
       "5846252           Scott  Jacquelyn  nh_white\n",
       "5959131          Parton    Douglas  nh_white\n",
       "12031764          Knapp       Liza  nh_white\n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "NGRAMS = 2\n",
    "SAMPLE = 1000000\n",
    "EPOCHS = 15\n",
    "\n",
    "# Florida voter\n",
    "df = pd.read_csv('../dataverse_files/fl_reg_name_race.csv.gz')\n",
    "df.dropna(subset=['name_first', 'name_last'], inplace=True)\n",
    "sdf = df[df.race.isin(['multi_racial', 'native_indian', 'other', 'unknown']) == False].sample(SAMPLE, random_state=21)\n",
    "del df\n",
    "\n",
    "# Additional features\n",
    "sdf['name_last'] = sdf.name_last.str.title()\n",
    "\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8050a",
   "metadata": {},
   "source": [
    "##  Preprocessing the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc491a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words = 1166\n",
      "Max feature len = 26, Avg. feature len = 5\n"
     ]
    }
   ],
   "source": [
    "# last name only\n",
    "sdf['name_last_name_first'] = sdf['name_last']\n",
    "\n",
    "# build n-gram list\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "a = vect.fit_transform(sdf.name_last_name_first)\n",
    "vocab = vect.vocabulary_\n",
    "\n",
    "# sort n-gram by freq (highest -> lowest)\n",
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    #print(b, c, a[:, c].sum())\n",
    "    words.append((a[:, c].sum(), b))\n",
    "    #break\n",
    "words = sorted(words, reverse=True)\n",
    "words_list = [w[1] for w in words]\n",
    "num_words = len(words_list)\n",
    "print(\"num_words = %d\" % num_words)\n",
    "\n",
    "\n",
    "def find_ngrams(text, n):\n",
    "    a = zip(*[text[i:] for i in range(n)])\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi\n",
    "\n",
    "# build X from index of n-gram sequence\n",
    "X = np.array(sdf.name_last_name_first.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "\n",
    "# check max/avg feature\n",
    "X_len = []\n",
    "for x in X:\n",
    "    X_len.append(len(x))\n",
    "\n",
    "max_feature_len = max(X_len)\n",
    "avg_feature_len = int(np.mean(X_len))\n",
    "\n",
    "print(\"Max feature len = %d, Avg. feature len = %d\" % (max_feature_len, avg_feature_len))\n",
    "y = np.array(sdf.race.astype('category').cat.codes)\n",
    "\n",
    "# Split train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)\n",
    "X_train, X_calib, y_train, y_calib = train_test_split(X_train, y_train, test_size=.4, random_state=10, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99315eba",
   "metadata": {},
   "source": [
    "## Setting up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd9c351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480000 train sequences\n",
      "320000 calibration sequences\n",
      "200000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (480000, 20)\n",
      "X_calib shape: (320000, 20)\n",
      "X_test shape: (200000, 20)\n",
      "4 classes\n",
      "y_train shape: (480000,)\n",
      "y_calib shape: (320000,)\n",
      "y_test shape: (200000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import load_model\n",
    "\n",
    "max_features = num_words # 20000\n",
    "feature_len = 20 # avg_feature_len # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_calib), 'calibration sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=feature_len)\n",
    "X_calib = sequence.pad_sequences(X_calib, maxlen=feature_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=feature_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_calib shape:', X_calib.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_calib shape:', y_calib.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "064ab9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nonconformist.base import ClassifierAdapter\n",
    "from nonconformist.nc import ClassifierNc\n",
    "\n",
    "class MyClassifierAdapter(ClassifierAdapter):\n",
    "    def __init__(self, model, fit_params=None):\n",
    "        super(MyClassifierAdapter, self).__init__(model, fit_params)\n",
    "\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        '''\n",
    "            x is a numpy.array of shape (n_train, n_features)\n",
    "            y is a numpy.array of shape (n_train)\n",
    "            \n",
    "            Here, do what is necessary to train the underlying model\n",
    "            using the supplied training data\n",
    "        '''        \n",
    "        model = Sequential()\n",
    "        model.add(Embedding(num_words, 32, input_length=feature_len))\n",
    "        model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        # using sparse_categorical_crossentropy to meet requirements for y\n",
    "        #    as stated in the documentation of the class\n",
    "        model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "        model.fit(x, y, batch_size=batch_size, epochs=EPOCHS,\n",
    "          validation_split=0.1, verbose=1)\n",
    "        \n",
    "        model.save('../models/fl_voter_reg/lstm/fl_all_name_lstm_nonconform.h5')\n",
    "    \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "            Obtain predictions from the underlying model\n",
    "            \n",
    "            Make sure this function returns an output that is compatible with\n",
    "            the nonconformity function used. For default nonconformity functions,\n",
    "            output from this function should be class probability estimates in\n",
    "            a numpy.array of shape (n_test, n_classes)\n",
    "        '''\n",
    "        keras_model = keras.models.load_model('../models/fl_voter_reg/lstm/fl_all_name_lstm_nonconform.h5')\n",
    "        results = keras_model.predict(x)\n",
    "        return results\n",
    "    \n",
    "my_classifier = None # Initialize an object of your classifier's type\n",
    "model = MyClassifierAdapter(my_classifier)\n",
    "nc = ClassifierNc(model)\n",
    "icp = IcpClassifier(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8422f4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 19:33:37.984558: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "13500/13500 [==============================] - 278s 19ms/step - loss: 0.6896 - accuracy: 0.7496 - val_loss: 0.6127 - val_accuracy: 0.7759\n",
      "Epoch 2/15\n",
      "13500/13500 [==============================] - 247s 18ms/step - loss: 0.6150 - accuracy: 0.7744 - val_loss: 0.5944 - val_accuracy: 0.7837\n",
      "Epoch 3/15\n",
      "13500/13500 [==============================] - 270s 20ms/step - loss: 0.5977 - accuracy: 0.7807 - val_loss: 0.5835 - val_accuracy: 0.7889\n",
      "Epoch 4/15\n",
      "13500/13500 [==============================] - 254s 19ms/step - loss: 0.5833 - accuracy: 0.7858 - val_loss: 0.5734 - val_accuracy: 0.7892\n",
      "Epoch 5/15\n",
      "13500/13500 [==============================] - 247s 18ms/step - loss: 0.5729 - accuracy: 0.7890 - val_loss: 0.5690 - val_accuracy: 0.7914\n",
      "Epoch 6/15\n",
      "13500/13500 [==============================] - 247s 18ms/step - loss: 0.5676 - accuracy: 0.7906 - val_loss: 0.5651 - val_accuracy: 0.7944\n",
      "Epoch 7/15\n",
      "13500/13500 [==============================] - 247s 18ms/step - loss: 0.5626 - accuracy: 0.7920 - val_loss: 0.5633 - val_accuracy: 0.7946\n",
      "Epoch 8/15\n",
      "13500/13500 [==============================] - 246s 18ms/step - loss: 0.5611 - accuracy: 0.7926 - val_loss: 0.5585 - val_accuracy: 0.7973\n",
      "Epoch 9/15\n",
      "13500/13500 [==============================] - 247s 18ms/step - loss: 0.5595 - accuracy: 0.7934 - val_loss: 0.5594 - val_accuracy: 0.7953\n",
      "Epoch 10/15\n",
      "13500/13500 [==============================] - 247s 18ms/step - loss: 0.5541 - accuracy: 0.7954 - val_loss: 0.5566 - val_accuracy: 0.7972\n",
      "Epoch 11/15\n",
      "13500/13500 [==============================] - 250s 19ms/step - loss: 0.5521 - accuracy: 0.7962 - val_loss: 0.5536 - val_accuracy: 0.7968\n",
      "Epoch 12/15\n",
      "13500/13500 [==============================] - 247s 18ms/step - loss: 0.5507 - accuracy: 0.7957 - val_loss: 0.5530 - val_accuracy: 0.7993\n",
      "Epoch 13/15\n",
      "13500/13500 [==============================] - 246s 18ms/step - loss: 0.5530 - accuracy: 0.7950 - val_loss: 0.5526 - val_accuracy: 0.7985\n",
      "Epoch 14/15\n",
      "13500/13500 [==============================] - 246s 18ms/step - loss: 0.5508 - accuracy: 0.7956 - val_loss: 0.5536 - val_accuracy: 0.7992\n",
      "Epoch 15/15\n",
      "13500/13500 [==============================] - 254s 19ms/step - loss: 0.5483 - accuracy: 0.7965 - val_loss: 0.5517 - val_accuracy: 0.8004\n"
     ]
    }
   ],
   "source": [
    "# Training and calibrating the data using noncorformist\n",
    "icp.fit(X_train, y_train)\n",
    "icp.calibrate(X_calib, y_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e0a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining the predictions based on our model\n",
    "results = icp.predict(X_test, significance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b532428a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False,  True,  True],\n",
       "       [False, False,  True,  True],\n",
       "       [False,  True, False,  True],\n",
       "       [False, False, False,  True],\n",
       "       [False, False, False,  True],\n",
       "       [False,  True,  True,  True],\n",
       "       [False, False, False,  True],\n",
       "       [False, False, False,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [False, False, False,  True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample output\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b9ecd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cb61c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_races = np.unique(results,axis=0)\n",
    "cnt_races.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1065b",
   "metadata": {},
   "source": [
    "## Sample prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409efb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races = np.array(sorted(sdf.race.unique().tolist()))\n",
    "races.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79adeefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liberto</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weill</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smith</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jones</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trinidad</td>\n",
       "      <td>hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Longo</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Reynoso Luna</td>\n",
       "      <td>hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Yearwood</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Turner</td>\n",
       "      <td>nh_black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Gray</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         name_last      race\n",
       "0          Liberto  nh_white\n",
       "1            Weill  nh_white\n",
       "2            Smith  nh_white\n",
       "3            Jones  nh_white\n",
       "4         Trinidad  hispanic\n",
       "...            ...       ...\n",
       "9995         Longo  nh_white\n",
       "9996  Reynoso Luna  hispanic\n",
       "9997      Yearwood  nh_white\n",
       "9998        Turner  nh_black\n",
       "9999          Gray  nh_white\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = sdf.sample(frac=0.01, random_state=10)\n",
    "test_sample.reset_index(inplace=True)\n",
    "test_sample.drop(['index','name_first','name_last_name_first'], axis=1, inplace=True)\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d6699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encod_arr = np.array(test_sample.name_last.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "encod_arr = sequence.pad_sequences(encod_arr, maxlen=feature_len)\n",
    "\n",
    "out_arr = icp.predict(encod_arr, significance=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f445e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_series = []\n",
    "for i in range(out_arr.shape[0]):\n",
    "    pred_series.append(races[[x for x,i in enumerate(out_arr[i]) if i]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38480cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample['pred_race'] = pred_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8244b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "      <th>race</th>\n",
       "      <th>pred_race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liberto</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>[nh_white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weill</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>[nh_white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smith</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>[nh_black, nh_white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jones</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>[nh_black, nh_white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trinidad</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>[hispanic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Longo</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>[nh_white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Reynoso Luna</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>[hispanic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Yearwood</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>[nh_black, nh_white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Turner</td>\n",
       "      <td>nh_black</td>\n",
       "      <td>[nh_black, nh_white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Gray</td>\n",
       "      <td>nh_white</td>\n",
       "      <td>[nh_black, nh_white]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         name_last      race             pred_race\n",
       "0          Liberto  nh_white            [nh_white]\n",
       "1            Weill  nh_white            [nh_white]\n",
       "2            Smith  nh_white  [nh_black, nh_white]\n",
       "3            Jones  nh_white  [nh_black, nh_white]\n",
       "4         Trinidad  hispanic            [hispanic]\n",
       "...            ...       ...                   ...\n",
       "9995         Longo  nh_white            [nh_white]\n",
       "9996  Reynoso Luna  hispanic            [hispanic]\n",
       "9997      Yearwood  nh_white  [nh_black, nh_white]\n",
       "9998        Turner  nh_black  [nh_black, nh_white]\n",
       "9999          Gray  nh_white  [nh_black, nh_white]\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c120d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
